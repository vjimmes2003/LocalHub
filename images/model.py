import torch
import os
import time
from PIL import Image
from images.utils.models import load_model
from images.utils.config import MODEL_CONFIGS, NEGATIVE_PROMPT
from images.utils.upscaler import apply_upscale
from images.utils.hires_fix import apply_hires_fix
from PIL import ImageFilter

# Asegura carpeta outputs
if not os.path.exists("images\\outputs"):
    os.makedirs("images\\outputs")

LOADED_MODELS = {}

def get_or_load_model(model_key: str):
    if model_key not in LOADED_MODELS:
        LOADED_MODELS[model_key] = load_model(model_key)
    return LOADED_MODELS[model_key]

def generate_image(prompt: str, model_key: str, resolution: tuple, seed: int = None, upscaler_key: str = "none"):

    start_total = time.perf_counter()

    timestamp = int(time.time())
    config = MODEL_CONFIGS[model_key]
    width, height = resolution
    steps = config["steps"]
    guidance_scale = config["cfg_scale"]
    pipe = get_or_load_model(model_key)

    generator = torch.Generator(device="cuda" if torch.cuda.is_available() else "cpu")
    if seed is not None:
        generator.manual_seed(seed)
        print(f"ğŸ² Usando seed fija: {seed}")
    else:
        seed = generator.seed()
        print(f"ğŸ² Usando seed aleatoria: {seed}")

    print(f"\nğŸ–¼ï¸ Generando imagen con:")
    print(f"ğŸ“Œ Modelo: {model_key}")
    print(f"ğŸ“ ResoluciÃ³n: {width}x{height}")
    print(f"âš™ï¸ Steps: {steps} | CFG: {guidance_scale}")
    print(f"ğŸ§  Upscaler: {upscaler_key}")

    # GeneraciÃ³n
    start_pipe = time.perf_counter()
    result = pipe(
        prompt=prompt,
        height=height,
        width=width,
        num_inference_steps=steps,
        guidance_scale=guidance_scale,
        generator=generator,
        negative_prompt=NEGATIVE_PROMPT
    )
    print(f"ğŸ•’ Tiempo generaciÃ³n base: {time.perf_counter() - start_pipe:.2f} s")

    image_base = result.images[0]
    filename_base = f"output_{model_key}_{timestamp}_base.png"
    save_path_base = os.path.join("images\\outputs", filename_base)
    image_base.save(save_path_base, format="PNG")
    
    # Aplicar hires.fix solo a SD1.5
    if config["type"] == "sd15_safetensors":
        print("âœ¨ Aplicando Hires.Fix...")
        try:
            start_hires = time.perf_counter()
            image_final = apply_hires_fix(
                image=image_base,
                prompt=prompt,
                model_key=model_key,
                seed=seed,
                denoising_strength=0.25,
                upscale_factor=1.5
            )
            print(f"âœ… Hires.Fix aplicado con Ã©xito")
            print(f"ğŸ•’ Tiempo Hires.Fix: {time.perf_counter() - start_hires:.2f} s")
        except Exception as e:
            print(f"âš ï¸ Error en Hires.Fix: {e}")
            image_final = image_base
    else:
        print("â© Saltando Hires.Fix para modelos SDXL o no compatibles.")
        image_final = image_base

    # Upscaler si se indica
    if upscaler_key and upscaler_key.lower() != "none":
        print(f"ğŸ” Aplicando upscaler '{upscaler_key}'...")
        try:
            start_upscale = time.perf_counter()
            image_final = apply_upscale(image_final, upscaler_key)
            print(f"ğŸ•’ Tiempo upscale: {time.perf_counter() - start_upscale:.2f} s")
        except Exception as e:
            print(f"âš ï¸ Error aplicando upscale: {e}")

    # Guardar imagen final
    filename_final = f"output_{model_key}_{timestamp}_final.png"
    save_path_final = os.path.join("images\\outputs", filename_final)
    image_final.save(save_path_final, format="PNG")
    print(f"ğŸ’¾ Imagen guardada automÃ¡ticamente en: {save_path_final}")

    print(f"ğŸ•’ Tiempo TOTAL: {time.perf_counter() - start_total:.2f} s")

    return image_base, image_final
